########################################################################
# WEBSITE https://flowork.cloud
# File NAME : C:\FLOWORK\modules\youtube_keyword_researcher\processor.py total lines 419 
########################################################################

import os
import sys
import json
import re
import uuid
import csv
import traceback
import subprocess
import datetime
import math
import importlib
from collections import Counter
from flowork_kernel.api_contract import BaseModule, IExecutable

print("--- [YouTubeResearcher] System Check... ---", file=sys.stderr, flush=True)

def ensure_dependencies():
    missing = []
    try:
        import yt_dlp
    except ImportError:
        missing.append("yt-dlp")

    try:
        from faster_whisper import WhisperModel
    except ImportError:
        missing.append("faster-whisper")

    if missing:
        print(f"âš ï¸ [YouTubeResearcher] Libraries missing: {missing}. Installing...", file=sys.stderr, flush=True)
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install"] + missing)
            importlib.invalidate_caches()
            print("âœ… [YouTubeResearcher] Installation Complete!", file=sys.stderr, flush=True)
            return True
        except Exception as e:
            print(f"âŒ [YouTubeResearcher] Auto-install failed: {e}", file=sys.stderr, flush=True)
            return False
    else:
        print("âœ… [YouTubeResearcher] All libraries present. Skipping download.", file=sys.stderr, flush=True)
        return True

if ensure_dependencies():
    import yt_dlp
    from faster_whisper import WhisperModel
    DEPENDENCIES_OK = True
else:
    DEPENDENCIES_OK = False

STOPWORDS = {
    'the', 'and', 'is', 'in', 'to', 'of', 'a', 'for', 'on', 'with', 'as', 'this', 'it', 'that',
    'yang', 'dan', 'di', 'dari', 'ini', 'itu', 'untuk', 'dengan', 'adalah', 'ke', 'pada',
    'guys', 'halo', 'oke', 'nah', 'jadi', 'video', 'channel', 'subscribe', 'like', 'comment',
    'bisa', 'akan', 'atau', 'saya', 'kita', 'kalau', 'jika', 'sudah', 'tapi', 'ada'
}

class YouTubeKeywordResearcher(BaseModule, IExecutable):

    TIER = "architect"

    def __init__(self, module_id, services):
        super().__init__(module_id, services)
        self.logger_service = services.get("logger")
        self.temp_dir = os.path.join(os.getcwd(), "temp_research_audio")
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)

    def _clean_text(self, text):
        if not text: return []
        text = re.sub(r'[^a-zA-Z0-9\s]', '', text.lower())
        words = text.split()
        return [w for w in words if w not in STOPWORDS and len(w) > 2]

    def _sanitize_filename(self, filename):
        return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

    def _get_ydl_opts(self):
        return {
            'quiet': True,
            'extract_flat': False,
            'skip_download': True,
            'no_warnings': True,
            'nocheckcertificate': True,
            'cachedir': False, # [FIX] MATIKAN CACHE
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-us,en;q=0.5',
            }
        }

    def _download_metadata(self, url):
        opts = self._get_ydl_opts()
        with yt_dlp.YoutubeDL(opts) as ydl:
            return ydl.extract_info(url, download=False)

    def _download_audio(self, url):
        unique_id = uuid.uuid4().hex
        output_template = os.path.join(self.temp_dir, f'{unique_id}.%(ext)s')

        opts = self._get_ydl_opts()
        opts.update({
            'skip_download': False,
            'format': 'bestaudio/best',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'outtmpl': output_template,
        })

        with yt_dlp.YoutubeDL(opts) as ydl:
            ydl.extract_info(url, download=True)
            return os.path.join(self.temp_dir, f'{unique_id}.mp3')

    def _calculate_seo_score(self, title, description, tags):
        score = 0
        if not title: return 0
        title_words = self._clean_text(title)
        desc_lower = description.lower() if description else ""
        matches = sum(1 for word in title_words if word in desc_lower)
        score += min(30, matches * 5)
        if tags:
            tag_count = len(tags)
            if 5 <= tag_count <= 20: score += 20
            elif tag_count < 5: score += 10
            else: score += 15
        if len(desc_lower) > 200: score += 20
        elif len(desc_lower) > 50: score += 10
        if 20 <= len(title) <= 70: score += 10
        if tags and len(tags) > 0:
            tag_text = " ".join(tags).lower()
            tag_matches = sum(1 for word in title_words if word in tag_text)
            if tag_matches > 0: score += 20
            else: score += 10
        return min(100, score)

    def _calculate_engagement_rate(self, views, likes, comments):
        if not views or views == 0: return 0.0
        interactions = (likes or 0) + (comments or 0)
        rate = (interactions / views) * 100
        return round(rate, 2)

    def _estimate_earnings(self, views):
        if not views: return {"low": "$0", "high": "$0"}
        low_est = (views / 1000) * 0.50
        high_est = (views / 1000) * 4.00
        return {
            "low": f"${low_est:,.2f}",
            "high": f"${high_est:,.2f}",
            "avg_raw": (low_est + high_est) / 2
        }

    def _check_monetization_status(self, channel_subscribers, is_verified, raw_meta):
        status = "Unknown"
        if channel_subscribers and channel_subscribers > 1000:
             status = "Likely Monetized"
        else:
             status = "Not Monetized (Subs < 1k)"
             return status
        if is_verified:
            status = "MONETIZED (Verified)"
        if raw_meta.get('availability') == 'premium_only':
             status = "MONETIZED (Premium)"
        return status

    def _calculate_video_velocity(self, views, upload_date_str):
        if not views or not upload_date_str: return "N/A"
        try:
            upload_dt = datetime.datetime.strptime(upload_date_str, '%Y%m%d')
            now = datetime.datetime.now()
            diff = now - upload_dt
            hours = diff.total_seconds() / 3600
            if hours < 1: hours = 1
            velocity = views / hours
            return f"{velocity:,.0f} v/h"
        except:
            return "N/A"

    def _save_to_csv(self, data, folder_path, filename):
        if not folder_path or not os.path.isdir(folder_path):
            folder_path = self.temp_dir
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)

        full_path = os.path.join(folder_path, filename)

        trans_data = data.get("transcript_data")
        if isinstance(trans_data, dict):
            hook_text = trans_data.get("hook_text", "")[:200]
            preview_text = trans_data.get("full_text", "")[:500]
            hook_analysis = trans_data.get("hook_analysis", "N/A")
        else:
            hook_text = "N/A (Deep Scan Required)"
            preview_text = str(trans_data)
            hook_analysis = "N/A"

        csv_row = {
            "Video Title": data["meta"]["title"],
            "URL": data.get("source_url", ""),
            "Channel": data["channel_intel"]["name"],
            "Subscribers": data["channel_intel"]["subscribers"],
            "Monetization Status": data["financials"]["monetization_status"],
            "Est. Earnings (Low)": data["financials"]["est_earnings"]["low"],
            "Est. Earnings (High)": data["financials"]["est_earnings"]["high"],
            "Views": data["meta"]["views"],
            "Velocity": data["video_ballistics"]["velocity"],
            "Engagement Rate": f"{data['video_ballistics']['engagement_rate']}%",
            "SEO Score": data['video_ballistics']['seo_score'],
            "Top Keywords": ", ".join(data["seo_analysis"]["top_keywords"]),
            "Original Tags": ", ".join(data["meta"]["original_tags"]),
            "Hook (First 30s)": hook_text,
            "Hook Analysis": hook_analysis,
            "Transcript Preview": preview_text
        }

        with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=csv_row.keys())
            writer.writeheader()
            writer.writerow(csv_row)

        return full_path

    def _extract_inputs_recursive(self, payload):
        found = {}
        if isinstance(payload, dict):
            for k, v in payload.items():
                if k in ["video_url", "research_depth", "whisper_model", "output_folder"] and v:
                    found[k] = v

                if k in ["inputs", "params", "config"] and isinstance(v, dict):
                    nested = self._extract_inputs_recursive(v)
                    found.update(nested)
        return found

    def execute(self, payload, config, status_updater, mode="EXECUTE", **kwargs):
        def update_ui(msg, status="RUNNING"):
            print(f"ðŸ“¢ [Researcher] {msg}", file=sys.stderr, flush=True)
            if self.logger_service:
                try: self.logger_service.info(f"[YouTubeResearcher] {msg}")
                except: pass
            if status_updater:
                try: status_updater(msg, status)
                except Exception as e: print(f"âš ï¸ UI Update Error: {e}", file=sys.stderr)

        try:
            update_ui("ðŸš€ Initializing Research Module...", "STARTING")

            runtime_extracted = self._extract_inputs_recursive(payload)
            inputs = {**config, **runtime_extracted}

            if not DEPENDENCIES_OK:
                return self._error("Dependencies failed. Check logs.", update_ui)

            video_url = inputs.get("video_url")
            mode = inputs.get("research_depth", "Flash (Metadata Only)")
            whisper_model = inputs.get("whisper_model", "base")
            lang_hint = inputs.get("language_hint", "en")
            output_folder = inputs.get("output_folder")

            if not video_url:
                return self._error("âŒ Video URL is EMPTY!", update_ui)

            update_ui(f"ðŸ•µï¸ Scanning Target: {video_url}")
            update_ui(f"âš™ï¸ Mode: {mode} | AI Model: {whisper_model}")

            update_ui(f"ðŸ” Extracting Deep Metadata & Ballistics...")
            try:
                meta = self._download_metadata(video_url)
            except Exception as e:
                return self._error(f"âŒ YouTube Download Failed: {str(e)}", update_ui)

            title = meta.get('title', 'Unknown Video')
            desc = meta.get('description', '')
            tags = meta.get('tags', [])

            channel_name = meta.get('uploader', 'Unknown')
            channel_url = meta.get('uploader_url', '')
            channel_subs = meta.get('channel_follower_count', 0)
            is_verified = meta.get('channel_is_verified', False)
            views = meta.get('view_count', 0)
            likes = meta.get('like_count', 0)
            comments = meta.get('comment_count', 0)
            duration = meta.get('duration', 0)
            upload_date = meta.get('upload_date', '')
            thumbnail = meta.get('thumbnail', '')

            seo_score = self._calculate_seo_score(title, desc, tags)
            engagement_rate = self._calculate_engagement_rate(views, likes, comments)
            velocity = self._calculate_video_velocity(views, upload_date)
            est_earnings = self._estimate_earnings(views)
            monetization_status = self._check_monetization_status(channel_subs, is_verified, meta)

            result_data = {
                "source_url": video_url,
                "meta": {
                    "title": title, "views": views, "likes": likes, "comments": comments,
                    "upload_date": upload_date, "duration": duration, "original_tags": tags,
                    "thumbnail": thumbnail, "description_full": desc
                },
                "channel_intel": {
                    "name": channel_name, "url": channel_url, "subscribers": channel_subs,
                    "is_verified": is_verified, "channel_tags": meta.get('channel_tags', [])
                },
                "video_ballistics": {
                    "seo_score": seo_score, "engagement_rate": engagement_rate,
                    "velocity": velocity, "categories": meta.get('categories', [])
                },
                "financials": {
                    "est_earnings": est_earnings, "monetization_status": monetization_status
                },
                "transcript_data": "Not requested"
            }

            text_corpus = f"{title} {title} {title} {desc} " + " ".join(tags) * 5

            if "Deep" in mode:
                update_ui("ðŸ§  [Deep Mode] Initializing Neural Audio Processor...")
                audio_file = None
                try:
                    audio_file = self._download_audio(video_url)
                    update_ui(f"ðŸŽ™ï¸ Transcribing Audio Stream ({whisper_model})...")

                    model = WhisperModel(whisper_model, device="cpu", compute_type="int8")
                    segments, info = model.transcribe(audio_file, language=lang_hint if lang_hint else None)

                    full_text_segments = []
                    hook_text = ""
                    current_time = 0
                    for s in segments:
                        full_text_segments.append(s.text)
                        if current_time < 30:
                            hook_text += s.text + " "
                            current_time = s.end

                    full_text = " ".join(full_text_segments)

                    hook_analysis = "Neutral"
                    title_clean = self._clean_text(title)
                    hook_clean = hook_text.lower()
                    if any(w in hook_clean for w in title_clean):
                        hook_analysis = "STRONG (Title Keywords in Hook)"
                    else:
                        hook_analysis = "WEAK (No Keyword Match)"

                    result_data["transcript_data"] = {
                        "full_text": full_text,
                        "hook_text": hook_text.strip(),
                        "hook_analysis": hook_analysis,
                        "detected_language": info.language,
                        "duration": info.duration
                    }
                    text_corpus += f" {full_text}"
                    update_ui("âœ… Neural Transcription Complete!")

                except Exception as e:
                    self.logger_service.error(f"Deep Analysis Error: {e}")
                    update_ui(f"âš ï¸ Transcript Failed: {str(e)}", "WARNING")
                    result_data["transcript_data"] = f"Error: {str(e)}"
                finally:
                    if audio_file and os.path.exists(audio_file):
                        try: os.remove(audio_file)
                        except: pass

            update_ui("ðŸ“Š Running Semantic Analysis...")
            clean_words = self._clean_text(text_corpus)
            word_counts = Counter(clean_words)
            top_keywords = [item[0] for item in word_counts.most_common(30)]

            result_data["seo_analysis"] = {
                "top_keywords": top_keywords,
                "density": dict(word_counts.most_common(15))
            }

            update_ui("ðŸ’¾ Saving Mission Report (CSV)...")
            safe_title = self._sanitize_filename(title)
            csv_filename = f"Scout_{safe_title[:30]}_{uuid.uuid4().hex[:4]}.csv"

            try:
                saved_path = self._save_to_csv(result_data, output_folder, csv_filename)
                update_ui(f"âœ¨ Report Secured: {saved_path}", "SUCCESS")
            except Exception as e:
                update_ui(f"âš ï¸ Failed to save CSV: {e}", "WARNING")
                saved_path = "FAILED_TO_SAVE"

            return {
                "output_name": "success",
                "payload": {
                    "result_json": result_data,
                    "top_keywords": ", ".join(top_keywords),
                    "csv_file_path": saved_path,
                    "monetization": monetization_status,
                    "earnings": est_earnings["low"]
                }
            }

        except Exception as e:
            traceback.print_exc()
            return self._error(f"CRITICAL ERROR: {str(e)}", update_ui)

    def _error(self, msg, updater=None):
        print(f"âŒ [Researcher] RETURNING ERROR: {msg}", file=sys.stderr, flush=True)
        if self.logger_service:
             self.logger_service.error(f"[YouTubeResearcher] {msg}")
        if updater:
            updater(msg, "ERROR")
        return {
            "output_name": "error",
            "payload": {
                "error": msg
            }
        }
